{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "# read our cleaned data into a pandas dataframe, specifying which variables are dates\n",
    "oli_rfm = pd.read_csv('oli_all_for_rfm.csv', parse_dates = ['order_approved_at', \n",
    "                                                            'order_purchase_timestamp', \n",
    "                                                            'order_delivered_customer_date',\n",
    "                                                            'order_estimated_delivery_date'])\n",
    "\n",
    "print(\"oli_all lignes:\", oli_rfm.shape[0],\"colonnes:\", oli_rfm.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "oli_rfm = oli_rfm.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-launch",
   "metadata": {},
   "source": [
    "## Data Separation into 4 Different Time Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date to beginning of 2017\n",
    "before_time = dt.datetime.strptime(\"2016-12-30 23:59:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# set date to end of april 2017\n",
    "first_current_time = dt.datetime.strptime(\"2017-04-30 23:59:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# set date to end of august 2017\n",
    "second_current_time = dt.datetime.strptime(\"2017-08-31 23:59:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# set date to end of december 2017\n",
    "third_current_time = dt.datetime.strptime(\"2017-12-31 23:59:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# set date to end of april 2018\n",
    "fourth_current_time = dt.datetime.strptime(\"2018-04-30 23:59:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# set date to end of august 2018\n",
    "fifth_current_time = dt.datetime.strptime(\"2018-08-31 23:59:00\", \"%Y-%m-%d %H:%M:%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for period one : January 2017 to August 2017\n",
    "olist_model_group_two = oli_rfm[(oli_rfm[\"order_purchase_timestamp\"] > before_time) &\n",
    "                                (oli_rfm[\"order_purchase_timestamp\"] < second_current_time)].copy()\n",
    "\n",
    "print(\"timeframe one data lignes:\", olist_model_group_two.shape[0],\"colonnes:\", olist_model_group_two.shape[1])\n",
    "\n",
    "# dataframe for period two:  January 2017 to December 2017\n",
    "olist_model_group_three = oli_rfm[(oli_rfm[\"order_purchase_timestamp\"] > before_time) &\n",
    "                                (oli_rfm[\"order_purchase_timestamp\"] < third_current_time)].copy()\n",
    "\n",
    "print(\"timeframe two data lignes:\", olist_model_group_three.shape[0],\"colonnes:\", \n",
    "      olist_model_group_three.shape[1])\n",
    "\n",
    "# dataframe for period three: May 2017 to April 2018\n",
    "olist_model_group_four = oli_rfm[(oli_rfm[\"order_purchase_timestamp\"] > first_current_time) &\n",
    "                                (oli_rfm[\"order_purchase_timestamp\"] < fourth_current_time)].copy()\n",
    "\n",
    "print(\"timeframe three data  lignes:\", olist_model_group_four.shape[0],\"colonnes:\", \n",
    "      olist_model_group_four.shape[1])\n",
    "\n",
    "# dataframe for period four: September 2017 to August 2018\n",
    "olist_model_group_five = oli_rfm[(oli_rfm[\"order_purchase_timestamp\"] > second_current_time) &\n",
    "                                (oli_rfm[\"order_purchase_timestamp\"] < fifth_current_time)].copy()\n",
    "\n",
    "print(\"timeframe four data lignes:\", olist_model_group_five.shape[0],\"colonnes:\", \n",
    "      olist_model_group_five.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_rfm_total_function(df, current_time):\n",
    "    \"\"\" \n",
    "    Function to get the relevant variables for each time period, and also to aggregate that dataframe\n",
    "    to the customer level.\n",
    "    \n",
    "    Parameters:\n",
    "    df: period dataframe \n",
    "    current_time: end time of the dataframe period\n",
    "\n",
    "    Returns:\n",
    "    models_group: Returns the dataframe ready to be used for the models, agreggated at the customer level\n",
    "    \"\"\"\n",
    "    \n",
    "    df = get_rm_variables(df, \"most_recent_purchase\", \"order_purchase_timestamp\", 'max')\n",
    "    \n",
    "    # now that we have most recent purchase, we calculate the recency by subtracting the most recent purchase\n",
    "    # to the \"current date\", so recency is days since last transaction\n",
    "    df[\"Recency\"] =  current_time - (df[\"most_recent_purchase\"])\n",
    "    \n",
    "    df['Recency'] = df['Recency'].dt.days\n",
    "    \n",
    "    # get frequency\n",
    "    nb_orders_per_cust = df.groupby(\"customer_unique_id\").size()\n",
    "    nb_orders_per_cust = pd.DataFrame(nb_orders_per_cust)\n",
    "    nb_orders_per_cust.columns = [\"Frequency\"]\n",
    "    df = pd.merge(left = df.copy(), right = nb_orders_per_cust.copy(), how = \"outer\", on = \"customer_unique_id\")\n",
    "\n",
    "    # get monetary / total transaction value (over all orders of the customer)\n",
    "    df = get_rm_variables(df, \"Monetary\", \"total_payment_per_order\", 'sum')\n",
    "    \n",
    "    # get average review \n",
    "    df = get_rm_variables(df, 'avg_review_score_per_customer', \"review_score\", 'mean')\n",
    "    \n",
    "    # get average delivery time\n",
    "    df = get_round_rm_variables(df, 'avg_delivery_time_per_customer', 'delivery_time', 'mean')\n",
    "    \n",
    "    df = get_round_rm_variables(df, 'avg_difference_est_real_delivery_customer', 'difference_est_real_delivery',\n",
    "                                'mean')\n",
    "    \n",
    "    # get average nb of items per client\n",
    "    df = get_round_rm_variables(df, \"avg_nb_of_items_per_customer\", \"nb_of_items_per_order\",\n",
    "                                'mean')\n",
    "    \n",
    "    # get average nb of payment installments per customer\n",
    "    df = get_round_rm_variables(df, \"avg_payment_installments_per_customer\", \n",
    "                                \"total_payment_installments_per_order\",\n",
    "                                'mean')\n",
    "\n",
    "    # get frequent distance\n",
    "    grouped = df.groupby(\"customer_unique_id\")[\"distance_geopy\"].agg(\n",
    "    lambda x: pd.Series.mode(x)[0])\n",
    "\n",
    "    grouped = pd.DataFrame(grouped)\n",
    "    grouped.columns = [\"geopy_frequnt_customerseller_distance\"]\n",
    "\n",
    "    df = pd.merge(left = df.copy(), right = grouped.copy(), how = \"outer\", on = \"customer_unique_id\")\n",
    "    \n",
    "    print(\"df original group lignes:\", df.shape[0],\"colonnes:\", df.shape[1])\n",
    "\n",
    "    models_group = df.drop_duplicates(\"customer_unique_id\", keep = \"first\").copy()\n",
    "    models_group = models_group.set_index('customer_unique_id')\n",
    "    \n",
    "    models_group = models_group[['Monetary', 'Recency', 'Frequency', \n",
    "                               'review_score', \n",
    "                               'avg_nb_of_items_per_customer', \n",
    "                               'avg_payment_installments_per_customer',\n",
    "                               'delivery_time', 'difference_est_real_delivery',\n",
    "                               \"geopy_frequnt_customerseller_distance\"]]\n",
    "\n",
    "    print(\"new aggregated customer level lignes:\", models_group.shape[0],\"colonnes:\", models_group.shape[1])\n",
    "    return models_group\n",
    "\n",
    "\n",
    "def get_rm_variables(df, new_column_name, column_for_groupby, transformation):\n",
    "    \"\"\"\n",
    "    Function called by the group_rfm_total_function, to perform a groupby \n",
    "    \n",
    "    Parameters:\n",
    "    df: period time dataframe\n",
    "    new_column_name: name for the column that will be created by the groupby transformation\n",
    "    column_for_groupby: column that we wish to apply the transformation to\n",
    "    transformation: the transformation to apply on the groupby \n",
    "\n",
    "    Returns:\n",
    "    df: dataframe containing the original dataframe with the new column\n",
    "    \"\"\"\n",
    "    df[new_column_name] = 0\n",
    "    df[new_column_name] = df.groupby(\"customer_unique_id\")[column_for_groupby].transform(transformation)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_round_rm_variables(df, new_column_name, column_for_groupby, transformation):\n",
    "    \"\"\"\n",
    "    Function called by group_rfm_total_function, to perform a groupby and the round the result at the end.\n",
    "\n",
    "    Parameters:\n",
    "    df: period time dataframe\n",
    "    new_column_name: name for the column that will be created by the groupby transformation\n",
    "    column_for_groupby: column that we wish to apply the transformation to\n",
    "    transformation: the transformation to apply on the groupby \n",
    "\n",
    "    Returns:\n",
    "    df: dataframe containing the original dataframe with the new column\n",
    "    \"\"\"\n",
    "    \n",
    "    df[new_column_name] = 0\n",
    "    df[new_column_name] = round(df.groupby(\"customer_unique_id\")[column_for_groupby].transform(transformation))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_group_one  = group_rfm_total_function(olist_model_group_two, second_current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_group_two  = group_rfm_total_function(olist_model_group_three, third_current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_group_three  = group_rfm_total_function(olist_model_group_four, fourth_current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_group_four  = group_rfm_total_function(olist_model_group_five, fifth_current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-chicago",
   "metadata": {},
   "source": [
    "# Data for Timeframe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-heating",
   "metadata": {},
   "source": [
    "## RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# take just the three RFM variables from the dataframe for period one\n",
    "rfm_group_one = models_group_one[['Monetary', 'Recency', 'Frequency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_group_one.Recency.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_group_one.Frequency.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_group_one.Monetary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(rfm_group_one.Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_group_one['Frequency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create quantiles for the variables in the dataframe\n",
    "rfm_quantiles = rfm_group_one.quantile(q = [0.25, 0.5, 0.75])\n",
    "rfm_quantiles[\"Frequency\"][0.25] = 2\n",
    "rfm_quantiles[\"Frequency\"][0.5] = 3\n",
    "rfm_quantiles[\"Frequency\"][0.75] = 4\n",
    "\n",
    "# send quantile to dictionary\n",
    "rfm_quantiles = rfm_quantiles.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rmf_score_function(x, p, rfm_quantiles):\n",
    "    \"\"\"\n",
    "    Function to get a score based on the quantiles. 1 is highest, best, and 4 is lowest, worst. \n",
    "    Parameters:\n",
    "    x = value in question that is being compared to the quantile value\n",
    "    p = the variable, either : Monetary, Frequency\n",
    "    rfm_quantiles = quartiles dict\n",
    "\n",
    "    Returns:\n",
    "    Returns the score for each value\n",
    "    \"\"\"\n",
    "    if x >= rfm_quantiles[p][0.75]:\n",
    "        return 1\n",
    "    elif x >= rfm_quantiles[p][0.50]:\n",
    "        return 2\n",
    "    elif x >= rfm_quantiles[p][0.25]:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "    \n",
    "\n",
    "def Rmf_score_recency(x, p, rfm_quantiles): \n",
    "    \"\"\"\n",
    "    Function to get a score based on the quantiles. \n",
    "    The way the scoring is put in place is reversed compared to the previous function. \n",
    "    1 is still best. \n",
    "   \n",
    "    Parameters:\n",
    "    x = value in question that is being compared to the quantile value\n",
    "    p = the variable, either : Monetary, Frequency\n",
    "    rfm_quantiles = quartiles dict\n",
    "\n",
    "    Returns:\n",
    "    Returns the score for each value\n",
    "    \"\"\"\n",
    "    if x <= rfm_quantiles[p][0.25]:\n",
    "        return 1\n",
    "    elif x <= rfm_quantiles[p][0.50]:\n",
    "        return 2\n",
    "    elif x <= rfm_quantiles[p][0.75]:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_group_one['R_score'] = rfm_group_one['Recency'].apply(Rmf_score_recency, args = ('Recency', \n",
    "                                                                                     rfm_quantiles))\n",
    "rfm_group_one['F_score'] = rfm_group_one['Frequency'].apply(Rmf_score_function, args = ('Frequency', \n",
    "                                                                                        rfm_quantiles))\n",
    "rfm_group_one['M_score'] = rfm_group_one['Monetary'].apply(Rmf_score_function, args = ('Monetary', \n",
    "                                                                                       rfm_quantiles))\n",
    "\n",
    "rfm_group_one['RFM_total_class'] = rfm_group_one.R_score.map(str) + rfm_group_one.F_score.map(str) \\\n",
    "                                       + rfm_group_one.M_score.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfm_get_label(df):\n",
    "    \"\"\"\n",
    "    Function to get labels for each data point according to the RFM scores.\n",
    "\n",
    "    Parameters:\n",
    "    df: dataframe containing the scores for each data point\n",
    "\n",
    "    Returns:\n",
    "    The labels for each data points.\n",
    "    \"\"\"\n",
    "    \n",
    "    if ((df['R_score'] == 1) and (df['F_score'] <= 2) and (df['M_score'] <= 2)):\n",
    "        return 'Top Customers'\n",
    "    \n",
    "    elif ((df['R_score'] == 1) and (df['F_score'] <= 3)):\n",
    "        return 'Active Customers'\n",
    "    \n",
    "    elif ((df['R_score'] == 2) and (df['F_score'] <= 3) and (df['M_score'] <=2)):\n",
    "        return 'Emerging Customers'\n",
    "    \n",
    "    elif ((df['R_score'] <= 2)):\n",
    "        return 'Unsteady Customers'\n",
    "    \n",
    "    \n",
    "    elif ((df['R_score'] == 4) and (df['F_score']) >= 3 and (df['M_score'] >= 3)):\n",
    "        return 'Lost Customers'\n",
    "    \n",
    "    elif ((df['R_score'] == 4) and (df['F_score'] >= 3) and (df['M_score'] <=2)):\n",
    "        return 'Inactive Customers'\n",
    "    \n",
    "    elif ((df['R_score'] == 3) and (df['F_score'] >= 3) and (df['M_score'] >=3)):\n",
    "        return 'Potentially Lost Customers'\n",
    "\n",
    "    else:\n",
    "        return 'At Risk Customers'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Customers  \n",
    "# Active Customers (recent but usual don't combine high monetary and high frequency like the top customers)\n",
    "# Emerging Customers (a little less recent than active customers)\n",
    "# Unsteady Customers (quite recent but didn't get into other 'good' categories, plus people who are recent but\n",
    "# not frequent at all)\n",
    "\n",
    "# At Risk Customers (no so recent anymore)\n",
    "# Potentially Lost Customers (not recent and not too frequent either)\n",
    "# Inactive Customers (long time ago, not recent at all, but high monetary)\n",
    "# Lost Customers (long time ago, not frequent, low monetary)\n",
    "\n",
    "rfm_group_one['rfm_label'] = rfm_group_one.apply(rfm_get_label, axis = 1)\n",
    "\n",
    "rfm_group_one['rfm_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values= ['Labels', 'Number of Customers'],\n",
    "                line_color='darkslategray',\n",
    "                fill_color='lightskyblue',\n",
    "                align='left'),\n",
    "    cells=dict(values=[['Unsteady Customers', 'At Risk Customers', 'Inactive Customers', 'Lost Customers',\n",
    "                        'Potentially Lost Customers', 'Active Customers', 'Emerging Customers', 'Top Customers'],\n",
    "                       [10405, 2761, 2662, 2635, 2626, 157, 124, 19]], \n",
    "               line_color='darkslategray',\n",
    "               fill_color='lightcyan',\n",
    "               align='left'))\n",
    "])\n",
    "\n",
    "fig.update_layout(width=500, height= 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# plot the clusters vs their recency\n",
    "df = px.data.tips()\n",
    "fig = px.box(rfm_group_one, x ='rfm_label', y = 'Recency', color = \"rfm_label\")\n",
    "fig.update_layout(showlegend = False, font_size = 14, width = 700, height = 600, \n",
    "                  yaxis_title = \"Recency / Most Recent Order per Customer\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(rfm_group_one, x ='rfm_label', y = 'Monetary', color = \"rfm_label\")\n",
    "fig.update_layout(showlegend = False, font_size = 14, width = 700, height = 600,\n",
    "                 yaxis_title = \"Monetary / Total Spent per Customer\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(rfm_group_one, x ='rfm_label', y = 'Frequency', color = \"rfm_label\")\n",
    "fig.update_layout(showlegend = False, font_size = 14, width = 700, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-administrator",
   "metadata": {},
   "source": [
    "## Data for Timeframe 1 K-Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_period_one = models_group_one[['Monetary', 'Recency', 'Frequency', \n",
    "                                 'review_score',\n",
    "                                 'avg_payment_installments_per_customer', \n",
    "                                 'delivery_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-investing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# plot the boxplots without the monetary variable\n",
    "\n",
    "y2 = models_group_one[\"Frequency\"]\n",
    "y3 = models_group_one[\"review_score\"]\n",
    "y4 = models_group_one[\"avg_payment_installments_per_customer\"]\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Box(y = y2, name = 'Frequency per Customer',\n",
    "                marker_color = 'burlywood'))\n",
    "fig.add_trace(go.Box(y = y3, name = 'Average Review Score per Customer',\n",
    "                marker_color = 'royalblue'))\n",
    "fig.add_trace(go.Box(y = y4, name = 'Average Payment Instalments per Customer',\n",
    "                marker_color = 'rebeccapurple'))\n",
    "\n",
    "fig.update_layout(showlegend = False, font_size = 14,\n",
    "                 width = 900, height = 650)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = models_group_one\n",
    "fig = px.histogram(df, x = \"Recency\",\n",
    "                   marginal = \"box\")\n",
    "fig.update_layout(showlegend = False, font_size = 14, xaxis_title = \"Recency / Most Recent Order per Customer\",\n",
    "                 width = 700, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = models_group_one\n",
    "fig = px.histogram(df, x = \"Monetary\",\n",
    "                   marginal = \"box\")\n",
    "fig.update_layout(showlegend = False, font_size = 14, xaxis_title = \"Monetary / Total Spent per Customer\",\n",
    "                 width = 700, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = models_group_one\n",
    "fig = px.histogram(df, x = 'delivery_time',\n",
    "                   marginal = \"box\")\n",
    "fig.update_layout(showlegend = False, font_size = 14, xaxis_title = \"Average Delivery Time per Customer\",\n",
    "                 width = 700, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_period_one.quantile(q = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_freq(df):\n",
    "    \"\"\"\n",
    "    Function to pre-process the Frequency data points, before using the Power Transform\n",
    "\n",
    "    Parameters:\n",
    "    df: dataframe for a given time period\n",
    "\n",
    "    Returns:\n",
    "    df: returns the dataframe, with Frequency, pre-processed before the power transform\n",
    "    \"\"\"\n",
    "    \n",
    "    quants = df.quantile(q = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "    \n",
    "    quants[\"Frequency\"][0.4] = 2\n",
    "    quants[\"Frequency\"][0.5] = 3\n",
    "    quants[\"Frequency\"][0.6] = 4\n",
    "    quants[\"Frequency\"][0.7] = 5\n",
    "    quants[\"Frequency\"][0.8] = 6\n",
    "    quants[\"Frequency\"][0.9] = 7\n",
    "    \n",
    "    #send quantile to dictionary\n",
    "    quants = quants.to_dict()\n",
    "    \n",
    "    df['F_score'] = df['Frequency'].apply(preproc_score_function, args = ('Frequency', quants))\n",
    "\n",
    "    df['M_score'] = df['Monetary']\n",
    "   \n",
    "    df['R_score'] = df['Recency']\n",
    "    \n",
    "    df['rev_score'] = df['review_score']\n",
    "    \n",
    "    df['pay_inst_score'] = df['avg_payment_installments_per_customer']\n",
    "        \n",
    "    df['del_time'] = df['delivery_time']\n",
    "    \n",
    "    return df\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_score_function(x, p, rfm_quantiles):\n",
    "    \"\"\"\n",
    "    Function called by preproc_freq\n",
    "    \n",
    "    # where 10 is higher (best) 1 is lower (bad)\n",
    "    # the lower the frequency, the worse the score\n",
    "    # Arguments (x = value, p = Frequency, rfm_quantiles = quartiles dict)\n",
    "\n",
    "    Parameters:\n",
    "    x = value in question that is being compared to the quantile value\n",
    "    p = the variable\n",
    "    rfm_quantiles = quartiles dict\n",
    "\n",
    "    Returns:\n",
    "    Returns a score from 1 to 10\n",
    "    \"\"\"\n",
    "        \n",
    "    if x <= rfm_quantiles[p][0.1]:\n",
    "        return 1\n",
    "    elif x <= rfm_quantiles[p][0.2]:\n",
    "        return 2\n",
    "    elif x <= rfm_quantiles[p][0.3]:\n",
    "        return 3\n",
    "    elif x <= rfm_quantiles[p][0.4]:\n",
    "        return 4\n",
    "    elif x <= rfm_quantiles[p][0.5]:\n",
    "        return 5\n",
    "    elif x <= rfm_quantiles[p][0.6]:\n",
    "        return 6\n",
    "    elif x <= rfm_quantiles[p][0.7]:\n",
    "        return 7\n",
    "    elif x <= rfm_quantiles[p][0.8]:\n",
    "        return 8\n",
    "    elif x <= rfm_quantiles[p][0.9]:\n",
    "        return 9\n",
    "    else:\n",
    "        return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfm_scaled = preproc_freq(X_period_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def my_pre_process(df):\n",
    "    \"\"\"\n",
    "    Function which applies the Power Transform to all the variables.\n",
    "    \n",
    "    Parameters:\n",
    "    df: the dataframe containing the variables to be processed\n",
    "\n",
    "    Returns:\n",
    "    X_rfm_scaled: dataframe containing variables after the power transform has been applied\n",
    "    \"\"\"\n",
    "    \n",
    "    #scaler = StandardScaler()\n",
    "    #qt = QuantileTransformer(n_quantiles = 10, random_state=0)\n",
    "    \n",
    "    pt = PowerTransformer()\n",
    "\n",
    "    X_rfm_scaled = pt.fit_transform(df.copy())\n",
    "\n",
    "    X_rfm_scaled = pd.DataFrame(X_rfm_scaled, index = df.index, columns = df.columns)\n",
    "    \n",
    "    return X_rfm_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfm_scaled = my_pre_process(X_rfm_scaled[['M_score', 'R_score', 'F_score',\n",
    "                                            \"rev_score\", 'pay_inst_score','del_time']].copy())\n",
    "  \n",
    "X_rfm_scaled.columns = ['Monetary', 'Recency', 'Frequency', 'review_score', \n",
    "                        'avg_payment_installments_per_customer', 'delivery_time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "y1 = X_rfm_scaled[\"Monetary\"]\n",
    "y2 = X_rfm_scaled[\"Recency\"]\n",
    "y3 = X_rfm_scaled[\"Frequency\"]\n",
    "\n",
    "y4 = X_rfm_scaled[\"review_score\"]\n",
    "y5 = X_rfm_scaled[\"avg_payment_installments_per_customer\"]\n",
    "y6 = X_rfm_scaled['delivery_time']\n",
    " \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Box(y = y1, name = 'Monetary / Total Spent per Customer',\n",
    "                marker_color = 'indianred'))\n",
    "fig.add_trace(go.Box(y = y2, name = 'Recency / Most Recent Order per Customer',\n",
    "                marker_color = 'lightseagreen'))\n",
    "fig.add_trace(go.Box(y = y3, name = 'Frequency per Customer',\n",
    "                marker_color = 'burlywood'))\n",
    "\n",
    "fig.add_trace(go.Box(y = y4, name = 'Avg Review Score',\n",
    "                marker_color = 'royalblue'))\n",
    "fig.add_trace(go.Box(y = y5, name = 'Avg Payment Instalments per Customer',\n",
    "                marker_color = 'rebeccapurple'))\n",
    "fig.add_trace(go.Box(y = y6, name = 'Avg Delivery Time',\n",
    "                marker_color = \"goldenrod\"))\n",
    "\n",
    "fig.update_layout(showlegend = False, font_size = 14,\n",
    "             width = 700, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = X_rfm_scaled\n",
    "fig = px.histogram(df, x = \"delivery_time\",\n",
    "                   marginal = \"box\")\n",
    "fig.update_layout(showlegend = False, font_size = 14, xaxis_title = \"Avg Delivery Time per Customer\",\n",
    "                 width = 700, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-anniversary",
   "metadata": {},
   "source": [
    "Visualisations and Decisions for Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn import cluster, metrics\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (9,6)\n",
    "\n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k = (2,12))\n",
    "\n",
    "visualizer.fit(X_rfm_scaled)    # Fit the data to the visualizer\n",
    "visualizer.poof() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the clustering model and visualizer \n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k = (4,12), metric = 'calinski_harabasz', timings = False)\n",
    "\n",
    "visualizer.fit(X_rfm_scaled)    # Fit the data to the visualizer\n",
    "visualizer.poof() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the clustering model and visualizer \n",
    "model = KMeans(4)\n",
    "visualizer = SilhouetteVisualizer(model)\n",
    "\n",
    "visualizer.fit(X_rfm_scaled)    # Fit the data to the visualizer\n",
    "visualizer.poof()    # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the clustering model and visualizer \n",
    "model = KMeans(5)\n",
    "visualizer = SilhouetteVisualizer(model)\n",
    "\n",
    "visualizer.fit(X_rfm_scaled)    # Fit the data to the visualizer\n",
    "visualizer.poof()    # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from sklearn import cluster, metrics\n",
    "\n",
    "silhouettes = []\n",
    "for num_clusters in range(3,10):\n",
    "    cls = cluster.KMeans(n_clusters = num_clusters)\n",
    "                         #n_init = 50, init = 'random')\n",
    "    cls.fit(X_rfm_scaled)\n",
    "    silh = metrics.silhouette_score(X_rfm_scaled, cls.labels_)\n",
    "    silhouettes.append(silh)\n",
    "    \n",
    "plt.plot(range(3, 10), silhouettes, marker = 'o')\n",
    "\n",
    "## changes with n_init, I first got 2 as max and now it's 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "x = np.arange(3,10)\n",
    "\n",
    "fig = go.Figure(data = go.Scatter(x = x, y = silhouettes))\n",
    "fig.update_layout(showlegend = False, font_size = 14, xaxis_title = \"Number of Clusters\",\n",
    "                  yaxis_title = \"Silhouette Scores\",\n",
    "                  width = 700, height = 600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-privilege",
   "metadata": {},
   "source": [
    "## Data for Timeframe 1: KMeans with Determined Nb of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from sklearn import cluster, metrics\n",
    "\n",
    "# we choose 5 clusters for the k means\n",
    "cls = cluster.KMeans(n_clusters = 5)\n",
    "cls.fit(X_rfm_scaled)\n",
    "cls.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a dataframe that will contain the silhouette scores for the different time periods\n",
    "kmeans_silh = []\n",
    "kmeans_silh.append(metrics.silhouette_score(X_rfm_scaled, cls.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1_for_reunion = pd.concat([X_rfm_scaled.copy(), pd.Series(cls.labels_, index = X_rfm_scaled.index)], axis = 1)\n",
    "group1_for_reunion.columns = ['Monetary', 'Recency',\n",
    "                              'Frequency', \n",
    "                              'review_score', \n",
    "                              'avg_payment_installments_per_customer', \n",
    "                              'delivery_time',\n",
    "                              'cluster']\n",
    "\n",
    "group1_for_reunion[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_sankey_period_one = pd.DataFrame(group1_for_reunion[\"cluster\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-evans",
   "metadata": {},
   "source": [
    "Boxplot Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_df_period_one = pd.concat([X_period_one.copy(), group1_for_reunion[\"cluster\"].copy()], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def boxplot_individ_variable_visual(df, y_vari, yaxis_title):\n",
    "    \"\"\"\n",
    "    Function to get boxplots illustrating the clusters vs different variables\n",
    "    Parameters:\n",
    "    df: dataframe containing the variables and clusters\n",
    "    y_vari: variable for the y axis\n",
    "    yaxis_title: title of the y axis\n",
    "\n",
    "    Returns:\n",
    "    Returns the figure\n",
    "    \"\"\"\n",
    "    fig = px.box(df, x = \"cluster\", y = y_vari, color = \"cluster\")\n",
    "    \n",
    "    fig.update_layout(showlegend = False, font_size = 14, \n",
    "                      yaxis_title = yaxis_title, xaxis_title = \"Cluster\",\n",
    "                      width = 700, height = 600)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group1_for_reunion, \"Monetary\", \"Monetary / Total Spent per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group1_for_reunion, \"Frequency\", \"Frequency per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group1_for_reunion, \"Recency\", \"Recency / Most Recent Order per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group1_for_reunion, 'avg_payment_installments_per_customer',\n",
    "                               \"Avg Payments Instalments per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group1_for_reunion, 'review_score', \"Avg Review Score per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group1_for_reunion, 'delivery_time', \"Avg Delivery Time per Customer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-morrison",
   "metadata": {},
   "source": [
    "Plot Clusters with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "# use the 3 first PCA components\n",
    "pca = decomposition.PCA(n_components = 3)\n",
    "pca.fit(X_rfm_scaled)\n",
    "print(pca.explained_variance_ratio_.cumsum())\n",
    "X_trans = pca.transform(X_rfm_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the explained variance ratio of each axis\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "cls_graph = cluster.KMeans(n_clusters = 5)\n",
    "cls_graph.fit(X_rfm_scaled)\n",
    "\n",
    "fig = px.scatter(x = X_trans[:,0], y = X_trans[:,1], color = cls_graph.labels_)\n",
    "\n",
    "fig.update_layout(height = 600, width = 600, xaxis_title = \"F1 (24%)\", yaxis_title = \"F2 (20%)\")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(x = X_trans[:,0], y = X_trans[:,1], z = X_trans[:,2],\n",
    "              color = cls_graph.labels_, opacity = 0.45)\n",
    "fig.update_layout(height = 600, width = 600,\n",
    "                 xaxis_title = \"F1 (24%)\", yaxis_title = \"F2 (20%)\")\n",
    "                  #, zaxis_title = \"F3 (16%)\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-canon",
   "metadata": {},
   "source": [
    "## Data for Timeframe 1 : DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# DBScan on data for the first timeframe\n",
    "db_clust = DBSCAN(min_samples = 150, eps = 0.95).fit(X_rfm_scaled)\n",
    "db_clust.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_period_one = pd.concat([X_rfm_scaled.copy(), pd.Series(db_clust.labels_,\n",
    "                                                          index = X_rfm_scaled.index)], axis = 1)\n",
    "db_period_one.columns = ['Monetary', 'Recency',\n",
    "                         'Frequency', \n",
    "                         'review_score', \n",
    "                         'avg_payment_installments_per_customer', \n",
    "                         'delivery_time',\n",
    "                         'cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_period_one[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(db_period_one, \"Monetary\", \"Monetary / Total Spent per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(db_period_one, \"Recency\", \"Recency / Most Recent Order per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(db_period_one, \"Frequency\", \"Frequency per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(db_period_one, 'review_score', \"Avg Review Score per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(db_period_one, 'avg_payment_installments_per_customer',\n",
    "                               \"Avg Payments Instalments per Customer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-parcel",
   "metadata": {},
   "source": [
    "# Data for Timeframe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_period_two = models_group_two[['Monetary', 'Recency', 'Frequency', \"review_score\", \n",
    "                                 'avg_payment_installments_per_customer', \n",
    "                                 'delivery_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing on the data for the second timeframe\n",
    "X_rfm_scaled2 = preproc_freq(X_period_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfm_scaled2 = my_pre_process(X_rfm_scaled2[['M_score', 'R_score', 'F_score', \n",
    "                                              'rev_score', \n",
    "                                              'pay_inst_score', \n",
    "                                              'del_time']])\n",
    "    \n",
    "X_rfm_scaled2.columns = ['Monetary', 'Recency', 'Frequency', \n",
    "                         'review_score', \n",
    "                         'avg_payment_installments_per_customer', \n",
    "                         'delivery_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = (9,6)\n",
    "\n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k = (2,12))\n",
    "\n",
    "visualizer.fit(X_rfm_scaled2)    # Fit the data to the visualizer\n",
    "visualizer.poof() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-recognition",
   "metadata": {},
   "source": [
    "## Data for Timeframe 2: Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sankey_dfs(scaled_df, labels):\n",
    "    \"\"\"\n",
    "    Function to get dataframes that will be used to produce a sankey diagram\n",
    "\n",
    "    Parameters:\n",
    "    scaled_df: processed data\n",
    "    labels: cluster labels\n",
    "\n",
    "    Returns:\n",
    "    for_newfit_sankey: dataframe containing just the cluster labels\n",
    "    group_new_fit: dataframe containing the processed data and it's corresponding cluster label\n",
    "    \"\"\"\n",
    "    \n",
    "    group_new_fit = pd.concat([scaled_df.copy(), pd.Series(labels, index = scaled_df.index)], axis = 1)\n",
    "    group_new_fit.columns = ['Monetary', 'Recency', 'Frequency', \"review_score\", \n",
    "                             \"avg_payment_installments_per_customer\", 'delivery_time',\n",
    "                             'cluster']\n",
    "    for_newfit_sankey = pd.DataFrame(group_new_fit[\"cluster\"])\n",
    "    \n",
    "    return for_newfit_sankey, group_new_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from sklearn import cluster, metrics\n",
    "\n",
    "# create a new kmeans model fitted to the second timeframe data\n",
    "cls2 = cluster.KMeans(n_clusters = 5)\n",
    "cls2.fit(X_rfm_scaled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the dataframe that records the silhouette scores for the kmeans models\n",
    "kmeans_silh.append(metrics.silhouette_score(X_rfm_scaled2, cls2.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_silh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the get_sankey_dfs fuction to our second timeframe data\n",
    "for_newfit_sankey2, group_new_fit2 = get_sankey_dfs(X_rfm_scaled2, cls2.labels_)\n",
    "group_new_fit2[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group_new_fit2, 'avg_payment_installments_per_customer',\n",
    "                               \"Avg Payments Instalments per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group_new_fit2, \"Frequency\", \"Frequency per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group_new_fit2, \"Recency\", \"Recency / Most Recent Order per Customer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-riverside",
   "metadata": {},
   "source": [
    "Use Model from 1st Period on 2nd Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2 = cls.predict(X_rfm_scaled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_previous_fitsankey2, group_nprev_fit2 = get_sankey_dfs(X_rfm_scaled2, predict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-fellow",
   "metadata": {},
   "source": [
    "Compute Rand Index Adjusted for chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_newfit_sankey2[\"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "# initialize dataframe to keep track of ARI scores\n",
    "kmeans_ari = []\n",
    "kmeans_ari.append(adjusted_rand_score(for_previous_fitsankey2[\"cluster\"], for_newfit_sankey2[\"cluster\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_ari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-costs",
   "metadata": {},
   "source": [
    "## Data for Timeframe 2 : DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db_clust_period_two = DBSCAN(min_samples = 150, eps = 0.80).fit(X_rfm_scaled2)\n",
    "db_clust_period_two.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_period_two = pd.concat([X_rfm_scaled2.copy(), pd.Series(db_clust_period_two.labels_,\n",
    "                                                           index = X_rfm_scaled2.index)], axis = 1)\n",
    "db_period_two.columns = ['Monetary', \n",
    "                         'Recency',\n",
    "                         'Frequency', \n",
    "                         'review_score', \n",
    "                         'avg_payment_installments_per_customer', \n",
    "                         'delivery_time',\n",
    "                         'cluster']\n",
    "\n",
    "db_period_two[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(db_period_two, \"Recency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(db_period_two, \"Monetary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(db_period_two, \"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-commercial",
   "metadata": {},
   "source": [
    "# Data for Timeframe 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_period_three = models_group_three[['Monetary', 'Recency', 'Frequency',\n",
    "                                     'review_score', \n",
    "                                     'avg_payment_installments_per_customer',\n",
    "                                     'delivery_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfm_scaled3 = preproc_freq(X_period_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfm_scaled3 = my_pre_process(X_rfm_scaled3[['M_score', 'R_score', 'F_score', \n",
    "                                              'rev_score', 'pay_inst_score', 'del_time']])\n",
    "\n",
    "X_rfm_scaled3.columns = ['Monetary', 'Recency', 'Frequency', \"review_score\", \n",
    "                         'avg_payment_installments_per_customer',\n",
    "                         'delivery_time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = (9,6)\n",
    "\n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k = (2,12))\n",
    "\n",
    "visualizer.fit(X_rfm_scaled3)    # Fit the data to the visualizer\n",
    "visualizer.poof() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-trunk",
   "metadata": {},
   "source": [
    "## Data for Timeframe 3: Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from sklearn import cluster, metrics\n",
    "\n",
    "# kmeans fitted to the third time period\n",
    "cls3 = cluster.KMeans(n_clusters = 5)\n",
    "cls3.fit(X_rfm_scaled3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_silh.append(metrics.silhouette_score(X_rfm_scaled3, cls3.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the get_sankey_dfs function to this timeframe for the sankey diagram later\n",
    "for_newfit_sankey3, group_new_fit3 = get_sankey_dfs(X_rfm_scaled3, cls3.labels_)\n",
    "group_new_fit3[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group_new_fit3,'avg_payment_installments_per_customer',\n",
    "                               \"Avg Payments Instalments per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group_new_fit3,  \"Frequency\", \"Frequency per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group_new_fit3, 'review_score', \"Avg Review Score per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group_new_fit3, \"Recency\", \"Recency / Most Recent Order per Customer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-plate",
   "metadata": {},
   "source": [
    "Use Model from 1st Period on 2nd Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict3 = cls.predict(X_rfm_scaled3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_previous_fitsankey3, group_prev_fit3  = get_sankey_dfs(X_rfm_scaled3, predict3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "kmeans_ari.append(adjusted_rand_score(for_previous_fitsankey3[\"cluster\"], for_newfit_sankey3[\"cluster\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_ari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-analysis",
   "metadata": {},
   "source": [
    "## Data for Timeframe 3: DBScan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db_clust_period_three = DBSCAN(min_samples = 150, eps = 0.90).fit(X_rfm_scaled3)\n",
    "db_clust_period_three.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_period_three = pd.concat([X_rfm_scaled3.copy(), pd.Series(db_clust_period_three.labels_,\n",
    "                                                          index = X_rfm_scaled3.index)], axis = 1)\n",
    "db_period_three.columns = ['Monetary', 'Recency',\n",
    "                           'Frequency', \n",
    "                           'review_score', \n",
    "                           'avg_payment_installments_per_customer', \n",
    "                           'delivery_time',\n",
    "                           'cluster']\n",
    "\n",
    "db_period_three[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(db_period_three, \"Recency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-solution",
   "metadata": {},
   "source": [
    "# Data for Timeframe 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_period_four = models_group_four[['Monetary', 'Recency', 'Frequency', \n",
    "                                   'review_score', \n",
    "                                   'avg_payment_installments_per_customer', \n",
    "                                   'delivery_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfm_scaled4 = preproc_freq(X_period_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfm_scaled4 = my_pre_process(X_rfm_scaled4[['M_score', 'R_score', 'F_score', \n",
    "                                              'rev_score', \n",
    "                                              'pay_inst_score', \n",
    "                                              'del_time']])\n",
    "    \n",
    "X_rfm_scaled4.columns = ['Monetary', 'Recency', 'Frequency', \n",
    "                         'review_score', \n",
    "                         'avg_payment_installments_per_customer', 'delivery_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = (9,6)\n",
    "\n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k = (2,12))\n",
    "\n",
    "visualizer.fit(X_rfm_scaled4)    # Fit the data to the visualizer\n",
    "visualizer.poof() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-collar",
   "metadata": {},
   "source": [
    "## Data for Timeframe 4: Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls4 = cluster.KMeans(n_clusters = 5)\n",
    "cls4.fit(X_rfm_scaled4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_silh.append(metrics.silhouette_score(X_rfm_scaled4, cls4.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_newfit_sankey4, group_new_fit4 = get_sankey_dfs(X_rfm_scaled4, cls4.labels_)\n",
    "group_new_fit4[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group_new_fit4, 'review_score', \"Avg Review Score per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group_new_fit4, \"Frequency\", \"Frequency per Customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(group_new_fit4, \"Recency\", \"Recency / Most Recent Order per Customer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-pendant",
   "metadata": {},
   "source": [
    "Use Model from 1st Period on 2nd Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict4 = cls.predict(X_rfm_scaled4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_previous_fitsankey4, group_prev_fit4 = get_sankey_dfs(X_rfm_scaled4, predict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "kmeans_ari.append(adjusted_rand_score(for_previous_fitsankey4[\"cluster\"], for_newfit_sankey4[\"cluster\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_silh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-contributor",
   "metadata": {},
   "source": [
    "## Data for Timeframe 4 : DBScan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db_clust_period_four = DBSCAN(min_samples = 150, eps = 0.90).fit(X_rfm_scaled4)\n",
    "db_clust_period_four.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_period_four = pd.concat([X_rfm_scaled4.copy(), pd.Series(db_clust_period_four.labels_,\n",
    "                                                          index = X_rfm_scaled4.index)], axis = 1)\n",
    "db_period_four.columns = ['Monetary', 'Recency',\n",
    "                           'Frequency', \n",
    "                           'review_score', \n",
    "                           'avg_payment_installments_per_customer', \n",
    "                           'delivery_time',\n",
    "                           'cluster']\n",
    "\n",
    "db_period_four[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_individ_variable_visual(db_period_four, \"Recency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-petite",
   "metadata": {},
   "source": [
    "# All Time Frame Period Groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sankey_df():\n",
    "    \"\"\"\n",
    "    Function to get a dataframe for the sankey diagram with labels and colours of the flows and clusters\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    Returns:\n",
    "    sankey_chart: Returns dataframe containing the colours and labels\n",
    "    \"\"\"\n",
    "    \n",
    "    sankey_chart = pd.DataFrame()\n",
    "\n",
    "    sankey_chart[\"colour\"] = [\"lightcoral\", \"gold\", \"plum\", \"deepskyblue\", \"bisque\",\n",
    "                              \"lightcoral\", \"gold\", \"plum\", \"deepskyblue\", \"bisque\",\n",
    "                              \"lightcoral\", \"gold\", \"plum\", \"deepskyblue\", \"bisque\",\n",
    "                              \"lightcoral\", \"gold\", \"plum\", \"deepskyblue\", \"bisque\",]\n",
    "        \n",
    "    sankey_chart[\"label\"] = [\"Unhappy Clients\", \"Active\", \"Best Clients\", \"Multiple Instalments Clients\", \"Inactive\",\n",
    "                             \"Unhappy Clients\", \"Active\", \"Best Clients\", \"Multiple Instalments Clients\", \"Inactive\",\n",
    "                             \"Unhappy Clients\", \"Active\", \"Best Clients\", \"Multiple Instalments Clients\", \"Inactive\",\n",
    "                             \"Unhappy Clients\", \"Active\", \"Best Clients\", \"Multiple Instalments Clients\", \"Inactive\"]\n",
    "    return sankey_chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sankey_newfit_df():\n",
    "    \"\"\"\n",
    "    Function to get a dataframe for the sankey diagram with labels and colours of the flows and clusters\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    Returns:\n",
    "    sankey_chart: Returns dataframe containing the colours and labels\n",
    "    \"\"\"\n",
    "    \n",
    "    sankey_chart = pd.DataFrame()\n",
    "\n",
    "    sankey_chart[\"colour\"] = [\"lightcoral\", \"gold\", \"plum\", \"deepskyblue\", \"bisque\",\n",
    "                              \"bisque\", \"deepskyblue\", \"gold\", \"lightcoral\", \"plum\",\n",
    "                              \"bisque\", \"deepskyblue\", \"gold\", \"plum\",  \"lightcoral\",\n",
    "                              \"bisque\", \"deepskyblue\", \"lightcoral\", \"gold\", \"plum\"]\n",
    "        \n",
    "    sankey_chart[\"label\"] = [\"Unhappy Clients\", \"Active\", \"Best Clients\", \"Multiple Instalments Clients\", \"Inactive\",\n",
    "                             \"Inactive\", \"Multiple Instalments Clients\", \"Active\", \"Unhappy Clients\", \"Best Clients\",\n",
    "                             \"Inactive\", \"Multiple Instalments Clients\", \"Active\", \"Best Clients\", \"Unhappy Clients\",\n",
    "                             \"Inactive\", \"Multiple Instalments Clients\", \"Unhappy Clients\", \"Active\", \"Best Clients\"]\n",
    "    return sankey_chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey_chart_previous_fit = make_sankey_df()\n",
    "\n",
    "sankey_chart_newfit = make_sankey_newfit_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_for_sankey(sankey_chart, nb_of_clust, for_sankey1, for_sankey2, for_sankey3, for_sankey4):\n",
    "    \"\"\"\n",
    "    Function that produces a dataframe that will build the sankey diagram\n",
    "\n",
    "    Parameters:\n",
    "    sankey_chart: dataframe resulting from our function make_sankey_df\n",
    "    nb_of_clust: number of clusters used in the kmeans\n",
    "    for_sankey1: dataframe with the info for timeframe 1\n",
    "    for_sankey2: dataframe with the info for timeframe 2\n",
    "    for_sankey3: dataframe with the info for timeframe 3\n",
    "    for_sankey4: dataframe with the info for timeframe 4\n",
    "\n",
    "    Returns:\n",
    "    sankey_chart: dataframe containing the information to build the sankey diagram\n",
    "    \"\"\"\n",
    "    \n",
    "    sankey_chart[\"value\"] = np.nan\n",
    "    sankey_chart[\"source\"] = np.nan\n",
    "    sankey_chart[\"target\"] = np.nan\n",
    "    \n",
    "    for i in range(0, nb_of_clust):\n",
    "        for_sankey2[for_sankey2[\"cluster\"] == i] = i + nb_of_clust\n",
    "\n",
    "    for i in range(0, nb_of_clust):\n",
    "        for_sankey3[for_sankey3[\"cluster\"] == i] = i + (nb_of_clust * 2)\n",
    "        \n",
    "    for i in range(0, nb_of_clust):\n",
    "        for_sankey4[for_sankey4[\"cluster\"] == i] = i + (nb_of_clust * 3)\n",
    "        \n",
    "    index = 0\n",
    "\n",
    "    for i in range(0, nb_of_clust):\n",
    "        for j in range(nb_of_clust, (nb_of_clust*2)):\n",
    "            \n",
    "            merge = pd.merge(left = for_sankey1[for_sankey1[\"cluster\"] == i].copy(), \n",
    "                             right = for_sankey2[for_sankey2[\"cluster\"] == j].copy(),\n",
    "                             how = \"inner\", on = \"customer_unique_id\")\n",
    "            \n",
    "            sankey_chart.loc[index,\"value\"] = merge.shape[0]\n",
    "            sankey_chart.loc[index,\"source\"] = i\n",
    "            sankey_chart.loc[index,\"target\"] = j\n",
    "            index += 1\n",
    "            \n",
    "            merge = pd.merge(left = for_sankey2[for_sankey2[\"cluster\"] == (i+nb_of_clust)].copy(), \n",
    "                             right = for_sankey3[for_sankey3[\"cluster\"] == (j+nb_of_clust)].copy(),\n",
    "                             how = \"inner\", on = \"customer_unique_id\")\n",
    "            \n",
    "            sankey_chart.loc[index,\"value\"] = merge.shape[0]\n",
    "            sankey_chart.loc[index,\"source\"] = (i+ nb_of_clust)\n",
    "            sankey_chart.loc[index,\"target\"] = (j+ nb_of_clust)\n",
    "            index += 1\n",
    "            \n",
    "            merge = pd.merge(left = for_sankey3[for_sankey3[\"cluster\"] == (i+(nb_of_clust*2))].copy(), \n",
    "                             right = for_sankey4[for_sankey4[\"cluster\"] == (j+(nb_of_clust*2))].copy(),\n",
    "                             how = \"inner\", on = \"customer_unique_id\")\n",
    "            \n",
    "            sankey_chart.loc[index,\"value\"] = merge.shape[0]\n",
    "            sankey_chart.loc[index,\"source\"] = (i+ (nb_of_clust*2))\n",
    "            sankey_chart.loc[index,\"target\"] = (j+ (nb_of_clust*2))\n",
    "            index += 1\n",
    "        \n",
    "    return sankey_chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_link_colours(df):\n",
    "    \"\"\"\n",
    "    Function to get the link colours\n",
    "\n",
    "    Parameters:\n",
    "    df: dataframe resulting from the make_df_for_sankey function\n",
    "\n",
    "    Returns:\n",
    "    df: dataframe with added link_colour column\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"link_colour\"] = np.nan\n",
    "    df.link_colour[(df[\"source\"] == 0) | (df[\"source\"] == 5)| (df[\"source\"] == 10)] = \"lightcoral\"\n",
    "    df.link_colour[(df[\"source\"] == 1) |(df[\"source\"] == 6) |(df[\"source\"] == 11)] = \"gold\"\n",
    "    df.link_colour[(df[\"source\"] == 2) | (df[\"source\"] == 7) | (df[\"source\"] == 12)] = \"plum\"\n",
    "    df.link_colour[(df[\"source\"] == 3)| (df[\"source\"] == 8) | (df[\"source\"] == 13)] = \"deepskyblue\"\n",
    "    df.link_colour[(df[\"source\"] == 4) | (df[\"source\"] == 9) |(df[\"source\"] == 14)] = \"bisque\"\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey_chart_previous_fit = make_df_for_sankey(sankey_chart_previous_fit.copy(), \n",
    "                                               5, for_sankey_period_one.copy(), \n",
    "                                               for_previous_fitsankey2.copy(),\n",
    "                                               for_previous_fitsankey3.copy(), \n",
    "                                               for_previous_fitsankey4.copy())\n",
    "\n",
    "sankey_chart_previous_fit = add_link_colours(sankey_chart_previous_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_link_newfit_colours(df):\n",
    "    \"\"\"\n",
    "    Function to get the link colours\n",
    "\n",
    "    Parameters:\n",
    "    df: dataframe resulting from the make_df_for_sankey function\n",
    "\n",
    "    Returns:\n",
    "    df: dataframe with added link_colour column\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"link_colour\"] = np.nan\n",
    "    df.link_colour[(df[\"source\"] == 0) | (df[\"source\"] == 8)| (df[\"source\"] == 14)] = \"lightcoral\"\n",
    "    df.link_colour[(df[\"source\"] == 1) |(df[\"source\"] == 7) |(df[\"source\"] == 12)] = \"gold\"\n",
    "    df.link_colour[(df[\"source\"] == 2) | (df[\"source\"] == 9) | (df[\"source\"] == 13)] = \"plum\"\n",
    "    df.link_colour[(df[\"source\"] == 3)| (df[\"source\"] == 6) | (df[\"source\"] == 11)] = \"deepskyblue\"\n",
    "    df.link_colour[(df[\"source\"] == 4) | (df[\"source\"] == 5) |(df[\"source\"] == 10)] = \"bisque\"\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey_chart_new_fit = make_df_for_sankey(sankey_chart_newfit.copy(), \n",
    "                                          5, for_sankey_period_one.copy(), \n",
    "                                          for_newfit_sankey2.copy(),\n",
    "                                          for_newfit_sankey3.copy(), \n",
    "                                          for_newfit_sankey4.copy())\n",
    "\n",
    "sankey_chart_new_fit = add_link_newfit_colours(sankey_chart_new_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_previous_fitsankey2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_my_sankey(sankey_chart):\n",
    "    \"\"\"\n",
    "    Function to plot the sankey_chart, for the version with the predicted labels from the KMeans on \n",
    "    the first timeframe\n",
    "\n",
    "    Parameters:\n",
    "    sankey_chart : df resulting from the make_df_for_sankey function\n",
    "\n",
    "    Returns:\n",
    "    sankey figure\n",
    "\n",
    "    \"\"\"\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        arrangement = 'fixed',\n",
    "        node = dict(\n",
    "          pad = 15,\n",
    "          thickness = 20,\n",
    "          line = dict(color = \"black\", width = 0.5),\n",
    "          label = sankey_chart['label'].dropna(axis=0, how='any'),\n",
    "        color = sankey_chart['colour'].dropna(axis = 0, how = \"any\"),\n",
    "            x = [1e-09, 1e-09, 1e-09, 1e-09, 1e-09, \n",
    "                 0.33, 0.33, 0.33, 0.33, 0.33,\n",
    "                 0.60, 0.60, 0.60, 0.60, 0.60, \n",
    "                 1, 1, 1, 1, 1],\n",
    "            y = [0.75, 0.25, 0.14, 0.60, 0.42,\n",
    "                 0.85, 0.22, 0.08, 0.65, 0.44,\n",
    "                 0.95, 0.20, 0.04, 0.70, 0.45,\n",
    "                 1, 0.15, 0.02, 0.74, 0.42]\n",
    "        ),\n",
    "        link = dict(\n",
    "          source = sankey_chart['source'],\n",
    "          target = sankey_chart['target'],\n",
    "          value = sankey_chart['value'],\n",
    "        color = sankey_chart[\"link_colour\"]))])\n",
    "    \n",
    "    fig.update_layout(title_text=\"Sankey Diagram\", font_size=10,\n",
    "                     autosize = False,\n",
    "                      width = 900,\n",
    "                      height = 600)\n",
    "    \n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_my_sankey(sankey_chart_previous_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_my_sankey_re(sankey_chart):\n",
    "    \"\"\"\n",
    "    Function to plot the sankey_chart, for the refitted K Means models\n",
    "\n",
    "    Parameters:\n",
    "    sankey_chart : df resulting from the make_df_for_sankey function\n",
    "\n",
    "    Returns:\n",
    "    sankey figure\n",
    "\n",
    "    \"\"\"\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        arrangement = 'fixed',\n",
    "        node = dict(\n",
    "          pad = 15,\n",
    "          thickness = 20,\n",
    "          line = dict(color = \"black\", width = 0.5),\n",
    "          label = sankey_chart['label'].dropna(axis=0, how='any'),\n",
    "        color = sankey_chart['colour'].dropna(axis = 0, how = \"any\"),\n",
    "            x = [1e-09, 1e-09, 1e-09, 1e-09, 1e-09, \n",
    "                 0.33, 0.33, 0.33, 0.33, 0.33,\n",
    "                 0.60, 0.60, 0.60, 0.60, 0.60, \n",
    "                 1, 1, 1, 1, 1],\n",
    "            y = [0.75, 0.25, 0.14, 0.60, 0.42,\n",
    "                 0.44, 0.65, 0.22, 0.85, 0.08,\n",
    "                 0.45, 0.70, 0.20, 0.04, 0.95,\n",
    "                 0.42, 0.74, 1, 0.15, 0.02]\n",
    "        ),\n",
    "        link = dict(\n",
    "          source = sankey_chart['source'],\n",
    "          target = sankey_chart['target'],\n",
    "          value = sankey_chart['value'],\n",
    "        color = sankey_chart[\"link_colour\"]))])\n",
    "    \n",
    "    fig.update_layout(title_text=\"Sankey Diagram\", font_size=10,\n",
    "                     autosize = False,\n",
    "                      width = 900,\n",
    "                      height = 600)\n",
    "    \n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_my_sankey_re(sankey_chart_new_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-honduras",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-train",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
